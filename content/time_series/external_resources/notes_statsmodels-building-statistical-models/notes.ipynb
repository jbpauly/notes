{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course: Building Statistical Models Using StatsModels\n",
    "### Course Autor: Janani Ravi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1: Exploring Statstical Properties Using StatsModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import getsource\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics.mean([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def mean(data):\n",
      "    \"\"\"Return the sample arithmetic mean of data.\n",
      "\n",
      "    >>> mean([1, 2, 3, 4, 4])\n",
      "    2.8\n",
      "\n",
      "    >>> from fractions import Fraction as F\n",
      "    >>> mean([F(3, 7), F(1, 21), F(5, 3), F(1, 3)])\n",
      "    Fraction(13, 21)\n",
      "\n",
      "    >>> from decimal import Decimal as D\n",
      "    >>> mean([D(\"0.5\"), D(\"0.75\"), D(\"0.625\"), D(\"0.375\")])\n",
      "    Decimal('0.5625')\n",
      "\n",
      "    If ``data`` is empty, StatisticsError will be raised.\n",
      "    \"\"\"\n",
      "    if iter(data) is data:\n",
      "        data = list(data)\n",
      "    n = len(data)\n",
      "    if n < 1:\n",
      "        raise StatisticsError('mean requires at least one data point')\n",
      "    T, total, count = _sum(data)\n",
      "    assert count == n\n",
      "    return _convert(total/n, T)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(getsource(statistics.mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important to consider removing Skewness in data for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2: Building Linear Models Using StatsModels\n",
    "\n",
    "## Regression\n",
    "### Requirements for using regression:\n",
    "- have zero mean\n",
    "- have constant  variance\n",
    "- be independent of each other\n",
    "- be independent of x\n",
    "- be normally distributed \n",
    "\n",
    "## Heteroscedasticity: non-constant variance\n",
    "\n",
    "- This can be a serious probelm building regression models\n",
    "- Stock prices are heteroscedastic \n",
    "    - Trending up over time\n",
    "    - Changing variance\n",
    "    \n",
    "### Detecting heteroscedasticity\n",
    "- Scatter plot of residuals will have a fanning out shape (delta)\n",
    "- R^2 is too good to be true (> 80%)\n",
    "\n",
    "### Implications\n",
    "- Overall regression equation is still unbiased\n",
    "- However estimates of regression parameters now biased\n",
    "- Confidence intervals may be worse than they appear\n",
    "- Using regression for prediction could be risky\n",
    "\n",
    "### Solutions\n",
    "- Transform the data\n",
    "    - use of log returns\n",
    "    - for stock prices\n",
    "        - use returns instead of price\n",
    "        - or use log price\n",
    "- Use different regression model\n",
    "    - weighted least squares\n",
    "    - generalized leasted squares\n",
    "    \n",
    "## Generalized Least Squares (GLS)\n",
    "A technique for fitting a “better” regression line\n",
    "between the residuals in an OLS model when they\n",
    "exhibit heteroscedasticity\n",
    "\n",
    "## Weighted Least Squares (WLS)\n",
    "Weighted least squares (WLS) is a specialization of GLS\n",
    "regression\n",
    "- OLS minimizes Mean Square Error (MSE)\n",
    "- WLS minimizes weighted MSE\n",
    "- What weights to use?\n",
    "- Need to specify - major drawback of WLS\n",
    "- **typically very hard to use in real life, b/c finding right weights is hard**\n",
    "- Use Cases\n",
    "    - Data is hetereoscedastic\n",
    "    - Regression should concentrate on\n",
    "    - specific data points\n",
    "    - Not all data points are equal\n",
    "    - The linear regression is part of another\n",
    "    - non-linear procedure\n",
    "- Drawbacks\n",
    "    - What weights to use?\n",
    "    - Need to specify - major drawback of WLS\n",
    "    - Need very precise weight estimates\n",
    "    - Sensitive to outliers\n",
    "    \n",
    "**Transforming data is a more commonly used way of dealing with heteroscedasticity than using GLS or WLS**\n",
    "\n",
    "## Generalized Linear Models\n",
    "A flexible generalization of ordinary linear regression that allows for non-normal y-variables, **even categorical**\n",
    "\n",
    "Elments of a GLM\n",
    "- Probability distribution of Y\n",
    "    - Normal\n",
    "    - Binomial\n",
    "    - Categorical\n",
    "    - more\n",
    "- Mean function\n",
    "    - Relationship between regression parameters and mean of Y\n",
    "- Link function\n",
    "    - Transformation to make X-Y relationship linear\n",
    "\n",
    "“It just works”: GLMs are a great way to fit linear models to binary or multinomial data without going deep into math\n",
    "\n",
    "## Robust Linear Models\n",
    "Modified regression algorithms that perform better than OLS in the presence of outliers (and also in cases of heteroscedasticity)\n",
    "- Regression using OLS works well when the basic assumptions about the underlying data are true\n",
    "- OLS regression is highly sensitive to outliers\n",
    "\n",
    "Usually superior to OLS regression Still not as popular\n",
    "- complex to understand\n",
    "- multiple competing algorithms\n",
    "- computationally intensive\n",
    "- not supported in Excel and other popular tools\n",
    "\n",
    "## Summary \n",
    "- Ordinary least squares regression makes many assumptions about data\n",
    "- Generalized or weighted least squares for heteroscedasticity\n",
    "- Generalized linear models for non-normal y-variables\n",
    "- Robust linear models to cope with outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3: Exploring Time Series Data Using StatsModels\n",
    "\n",
    "## Time Series\n",
    "- A time series is a sequence of data taken at successive and usually equally spaced points in time.\n",
    "\n",
    "- Time series models are especially vulnerable to problems of **non-stationarity**\n",
    "\n",
    "## Stationarity \n",
    "\n",
    "### Non-stationary Data\n",
    "- Mean changes over time\n",
    "- Variance changes over time\n",
    "- Autocorrelation changes over time\n",
    "- Applying regression to non-stationary data yield poor model\n",
    "    - inflated R^2\n",
    "    - Problems with heteroscedasticity\n",
    "\n",
    "### Stationary Data\n",
    "- Mean of time series does not change over time\n",
    "- Variance of time series does not change over time (homoscedasticity)\n",
    "- Autocorrelation does not change over time\n",
    "\n",
    "### Detecting Stationarity\n",
    "- Statistical tests exist to test for non-stationarit\n",
    "- In practice, simple forms of non-stationarity can be found from plotting data\n",
    "- More complex forms require statistical tests\n",
    "\n",
    "#### Visualization\n",
    "- Non-stationary\n",
    "    - trending in a certain direction (stocks trend up)\n",
    "    - periods of high and low volitility\n",
    "    - varying autocorrelation (spread changes)\n",
    "    \n",
    "### Fixing non-stationary data\n",
    "Make non-stationary data, stationary\n",
    "- Convert to log differences\n",
    "- Convert to returns\n",
    "\n",
    "## Time Series forecasting\n",
    "\n",
    "### Auto Regressive Model (AR(p))\n",
    "#### Autoregression Formula\n",
    "> y_t = A + B * y_t-1\n",
    "#### General Form of Linear Model\n",
    "> Y_t = c + ((p Σ i=1) 𝜙_i * X_t) + ε_t\n",
    "#### General Form of Autoregressive Model\n",
    "> Y_t = c + ((p Σ i=1) 𝜙_i * Y_t-i) + ε_t\n",
    "\n",
    "- Last p values of Y influence current value of Y\n",
    "- p is the moving time lag\n",
    "- **Future vlaues of Y depend on past values of Y and on current value of white noise**\n",
    "\n",
    "#### White noise error term: ε_t\n",
    "Make the same assumptions of white noise error term that we do with residuals in linear regression models\n",
    "- zero-mean\n",
    "- constant-variance\n",
    "- normally distributed\n",
    "- Independent and identically distributed (IID)\n",
    "\n",
    "AR models have **single** error term\n",
    "- models that depend on previous error terms are moving average (MA)\n",
    "\n",
    "### Moving Average Model (MA(q))\n",
    "Moving average of the last q values of ε (error)\n",
    "\n",
    "#### General Form of Moving Average Model\n",
    "> Y_t = 𝜇 + ε_t + 𝜽1 * ε_t-1 +...+ 𝜽_q ε_t-q\n",
    "\n",
    "- Value of Y depends on last q values of the white noise process\n",
    "- q is the moving time lag\n",
    "- **Future values of Y depend on pastvalues of white noise alone**\n",
    "\n",
    "### ARMA(p,q) Model\n",
    "Combination of AR and MA models\n",
    "\n",
    "#### General Form of Moving Average Model\n",
    "> Y_t = 𝜇 + ε_t + 𝜽_1 * ε_t-1 +...+ 𝜽_q * ε_t-q + 𝜙_1 * Y_t-1 +...+ 𝜙_p * Y_t-p\n",
    "- p is the lagger for AR\n",
    "- q is the lagger for MA\n",
    "- *Future values of Y depend on past values of Y and on current and past values of white noise**\n",
    "\n",
    "\n",
    "### Finding p,q for AR(p) and MA(q)\n",
    "```\n",
    "                    ---> Find q for MA(q) Model\n",
    "                ---> ACF Plot\n",
    "            ---> autocorrelation\n",
    "        ---> correlation\n",
    "start --\n",
    "        ---> Partial correlation\n",
    "            ---> partial autocorrelation \n",
    "                ---> PACF Plot\n",
    "                     ---> Find p for AR(q) Model\n",
    "```    \n",
    "\n",
    "#### Correlation\n",
    "The measure of the relationship between two items or variables\n",
    "\n",
    "#### Autocorrelation\n",
    "Measures the relationship between a variable’s current value and past value\n",
    "- ranges from -1 to 1\n",
    "    - 1 == perfect positive correlation\n",
    "    - -1 == perfect negative correlation\n",
    "\n",
    "#### Partial Autocorrelation\n",
    "Conceptually similar to autocorrelation; based on partial correlation of a series with lagged versions of itself\n",
    "\n",
    "#### ACF and PACF Plots\n",
    "- Lag-0 is always == 1\n",
    "    - time series data is always perfected self correlated with itself\n",
    "- Boundary shading is the bounds of statstical significance\n",
    "    - use this to check how many of the lags are statstically significant\n",
    "    \n",
    "#### Finding correct q and p values \n",
    "- ACF plot of an MA(q) process cuts off after q lags\n",
    "- PACF plot of an AR(p) process cuts off after p lags\n",
    "- If lags significance tapers off slowly/no abrupt cut-off then don't use a lag at all\n",
    "    - **MIGHT BE DIFFERENT FOR P AND Q RESPECTIVELY**\n",
    "    - This follow the **principle of parsimony** AKA Occam's Razor\n",
    "        - the simplest explanation is usually the right one\n",
    "**Process (For both ACF and PACF seperately)**\n",
    "1. Plot ACF/PACF\n",
    "2. Find lag cutoff (if no good cut off for BOTH ACF and PACF then probably non-stationary)\n",
    "    a. lag cutoff for ACF == p max \n",
    "    b. lag cuttoff for PACF == q max\n",
    "3. Test a few models ARMA models\n",
    "    a. p ranging from 0 to p max\n",
    "    b. q ranging from 0 to q max\n",
    "4. Select model with best score\n",
    "    a. AIC\n",
    "    b. BIC\n",
    "    c. HQIC\n",
    "\n",
    "#### Selecting a model \n",
    "##### AIC \n",
    "Akaike's Information Criterion\n",
    "- Estimates the relative information lost by the model\n",
    "- Lower score == less information lost\n",
    "    - Less information lost == better model\n",
    "\n",
    "##### BIC\n",
    "Bayesian Information Criterion\n",
    "- Similar to AIC\n",
    "- Lower score == less information lost\n",
    "    - Less information lost == better model\n",
    "    \n",
    "##### HQIC\n",
    "Hannan and Quinn Information Criterion\n",
    "- Again, lower score == less information lost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
